{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0989, 0.0585], -0.0841, [0.8006, 0.7631, 0.7307, 0.7025, 0.6776])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.tensor([[1.0, 2.0], [2.0, 1.0], [-1.0, -2.0]]) \n",
    "labels = torch.tensor([1, 0, 0]) \n",
    "initial_weights = torch.tensor([0.1, -0.2])\n",
    "initial_bias = torch.tensor(0.0) \n",
    "learning_rate = 0.1 \n",
    "epochs = 5\n",
    "\n",
    "def sigmoid_neuron(features, labels, initial_weights, initial_bias, learning_rate, epochs):\n",
    "    w = initial_weights.clone()\n",
    "    b = initial_bias.clone()\n",
    "    losses = []\n",
    "    eps = 1e-20\n",
    "    for _ in range(epochs):\n",
    "        pred = torch.sigmoid(w @ features.T + b)\n",
    "        loss = -torch.mean(torch.mul(labels, torch.log(pred+eps)) + torch.mul((1-labels), torch.log(1-pred+eps)))\n",
    "        losses.append(round(loss.item(), 4))\n",
    "\n",
    "        # sig(z) = 1 / (1 + e^(-z)), z = wx + b\n",
    "        # L = -(ylog(sig(z)) + (1-y)log(1 - sig(z)))\n",
    "        # dL/dw = (sig(z) - y)x\n",
    "        # dL/db = sig(z) - y\n",
    "\n",
    "        w -= learning_rate * torch.mean(torch.mul((pred - labels).unsqueeze(1), features), dim=0)\n",
    "        b -= learning_rate * torch.mean(pred - labels)\n",
    "\n",
    "    return [round(e, 4) for e in w.tolist()], round(b.item(), 4), losses\n",
    "\n",
    "sigmoid_neuron(features, labels, initial_weights, initial_bias, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133081</th>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111484</th>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448402</th>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254414</th>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272580</th>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year\n",
       "133081  2001\n",
       "111484  2006\n",
       "448402  1989\n",
       "254414  1997\n",
       "272580  2001"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/home/an/spbu_deep_learning/done\"\n",
    "train_x = pd.read_csv(f'{data_path}/train_x.csv', index_col=0)\n",
    "train_y = pd.read_csv(f'{data_path}/train_y.csv', index_col=0)\n",
    "test_x = pd.read_csv(f'{data_path}/test_x.csv')\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.1261,\n",
       "  -0.2034,\n",
       "  -1.051,\n",
       "  -0.3494,\n",
       "  -1.0502,\n",
       "  1.2616,\n",
       "  0.4137,\n",
       "  -1.1475,\n",
       "  2.1235,\n",
       "  -0.4904,\n",
       "  0.7656,\n",
       "  -0.4325,\n",
       "  1.7522,\n",
       "  11.6982,\n",
       "  8.987,\n",
       "  6.5921,\n",
       "  3.3813,\n",
       "  5.5368,\n",
       "  2.4356,\n",
       "  2.9917,\n",
       "  2.4621,\n",
       "  1.2084,\n",
       "  0.4421,\n",
       "  2.4105,\n",
       "  0.7774,\n",
       "  -0.4157,\n",
       "  -0.5242,\n",
       "  0.6327,\n",
       "  -0.7025,\n",
       "  1.0223,\n",
       "  1.0385,\n",
       "  -1.4954,\n",
       "  -1.2859,\n",
       "  1.687,\n",
       "  -0.1626,\n",
       "  -0.7063,\n",
       "  -0.3783,\n",
       "  0.1948,\n",
       "  0.8552,\n",
       "  1.3663,\n",
       "  -0.2249,\n",
       "  -0.1879,\n",
       "  -0.4951,\n",
       "  1.3973,\n",
       "  0.3444,\n",
       "  0.2164,\n",
       "  1.2698,\n",
       "  0.6251,\n",
       "  -1.0704,\n",
       "  -0.5806,\n",
       "  -2.0194,\n",
       "  0.2839,\n",
       "  -0.4351,\n",
       "  -0.9872,\n",
       "  -0.4606,\n",
       "  -0.4964,\n",
       "  0.4262,\n",
       "  0.3206,\n",
       "  -0.8494,\n",
       "  0.8067,\n",
       "  0.3319,\n",
       "  0.6233,\n",
       "  -0.1835,\n",
       "  -1.4181,\n",
       "  0.7365,\n",
       "  -1.4411,\n",
       "  0.3597,\n",
       "  0.6622,\n",
       "  -1.3785,\n",
       "  -0.7035,\n",
       "  1.4022,\n",
       "  -0.8445,\n",
       "  1.0985,\n",
       "  0.5402,\n",
       "  -1.0767,\n",
       "  -0.2261,\n",
       "  1.0861,\n",
       "  -1.8878,\n",
       "  -1.9887,\n",
       "  -1.0133,\n",
       "  -0.7579,\n",
       "  -0.4751,\n",
       "  -0.752,\n",
       "  -1.0093,\n",
       "  1.9194,\n",
       "  -0.695,\n",
       "  -0.3172,\n",
       "  0.1396,\n",
       "  0.2589,\n",
       "  0.0392],\n",
       " 0.0048,\n",
       " [43.8954, 43.8954, 43.8954, 43.8954, 43.8954])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_y = train_y[train_y['year'].isin([2001, 1961])]\n",
    "new_indices = new_train_y.index\n",
    "new_train_x = train_x.loc[new_indices]\n",
    "\n",
    "features = torch.tensor(new_train_x.values, dtype=torch.float32)\n",
    "labels = torch.tensor((new_train_y['year'] == 2001).astype(int).values, dtype=torch.float32)\n",
    "\n",
    "initial_weights = torch.randn(features.shape[1])\n",
    "initial_bias = torch.zeros(1)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "\n",
    "sigmoid_neuron(features, labels, initial_weights, initial_bias, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0989, 0.0585], -0.0841, [0.8006, 0.7631, 0.7307, 0.7025, 0.6776])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.tensor([[1.0, 2.0], [2.0, 1.0], [-1.0, -2.0]]) \n",
    "labels = torch.tensor([1, 0, 0]) \n",
    "initial_weights = torch.tensor([0.1, -0.2])\n",
    "initial_bias = torch.tensor(0.0) \n",
    "learning_rate = 0.1 \n",
    "epochs = 5\n",
    "\n",
    "def sigmoid_neuron_with_momentum(features, labels, initial_weights, initial_bias, learning_rate, epochs, momentum=0.9):\n",
    "    w = initial_weights.clone()\n",
    "    b = initial_bias.clone()\n",
    "    losses = []\n",
    "    eps = 1e-20\n",
    "    v_w = torch.zeros_like(w)\n",
    "    v_b = torch.zeros_like(b)\n",
    "    for _ in range(epochs):\n",
    "        pred = torch.sigmoid(w @ features.T + b)\n",
    "        loss = -torch.mean(torch.mul(labels, torch.log(pred+eps)) + torch.mul((1-labels), torch.log(1-pred+eps)))\n",
    "        losses.append(round(loss.item(), 4))\n",
    "\n",
    "        w -= torch.mul(momentum, v_w) + torch.mul(learning_rate, torch.mean(torch.mul((pred - labels).unsqueeze(1), features), dim=0))\n",
    "        b -= torch.mul(momentum, v_b) + torch.mul(learning_rate, torch.mean(pred - labels))\n",
    "\n",
    "    return [round(e, 4) for e in w.tolist()], round(b.item(), 4), losses\n",
    "\n",
    "sigmoid_neuron_with_momentum(features, labels, initial_weights, initial_bias, learning_rate, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
