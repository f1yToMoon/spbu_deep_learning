{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from dvclive import Live\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_MAPPING = {\n",
    "    \"0\": \"Ace\", \"1\": \"Akainu\", \"2\": \"Brook\", \"3\": \"Chopper\", \"4\": \"Crocodile\",\n",
    "    \"5\": \"Franky\", \"6\": \"Jinbei\", \"7\": \"Kurohige\", \"8\": \"Law\", \"9\": \"Luffy\",\n",
    "    \"10\": \"Mihawk\", \"11\": \"Nami\", \"12\": \"Rayleigh\", \"13\": \"Robin\", \"14\": \"Sanji\",\n",
    "    \"15\": \"Shanks\", \"16\": \"Usopp\", \"17\": \"Zoro\"\n",
    "}\n",
    "TEST_DATA_PATH = \"/home/an/spbu_deep_learning/classification/splitted/test\"\n",
    "TRAIN_DATA_PATH = \"/home/an/spbu_deep_learning/classification/splitted\"\n",
    "CSV_PATH = \"/home/an/spbu_deep_learning/classification/train_annotations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ace': 168,\n",
       " 'Akainu': 167,\n",
       " 'Brook': 178,\n",
       " 'Chopper': 170,\n",
       " 'Crocodile': 167,\n",
       " 'Franky': 170,\n",
       " 'Jinbei': 167,\n",
       " 'Kurohige': 170,\n",
       " 'Law': 175,\n",
       " 'Luffy': 97,\n",
       " 'Mihawk': 167,\n",
       " 'Nami': 181,\n",
       " 'Rayleigh': 167,\n",
       " 'Robin': 167,\n",
       " 'Sanji': 135,\n",
       " 'Shanks': 168,\n",
       " 'Usopp': 170,\n",
       " 'Zoro': 132}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_images_per_class(csv_path, labels_mapping):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    counts = {label: 0 for label in labels_mapping.values()}\n",
    "\n",
    "    for label in data['label']:\n",
    "        class_name = labels_mapping.get(str(label), None)\n",
    "        if class_name is not None:\n",
    "            counts[class_name] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "count_images_per_class(CSV_PATH, LABELS_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(csv_path, labels_mapping, test_size=0.2, random_state=42):\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    data['image_path'] = data['image_path'].apply(lambda p: os.path.normpath(p))\n",
    "\n",
    "    data['split'] = 'train'\n",
    "\n",
    "    for label in labels_mapping.keys():\n",
    "        class_data = data[data['label'] == int(label)]\n",
    "        _, test = train_test_split(class_data, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        data.loc[test.index, 'split'] = 'val'\n",
    "\n",
    "    return data\n",
    "\n",
    "NEW_CSV_PATH = \"/home/an/spbu_deep_learning/classification/new_annotations.csv\"\n",
    "\n",
    "splitted_data = split_train_test(CSV_PATH, LABELS_MAPPING, test_size=0.2)\n",
    "splitted_data.to_csv(NEW_CSV_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnePieceDataset(Dataset):\n",
    "    def __init__(self, images_dir, csv_path=None, labels_json=None, transform=None, split=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.is_train = csv_path is not None\n",
    "\n",
    "        if self.is_train:\n",
    "            import pandas as pd\n",
    "            self.data = pd.read_csv(csv_path)\n",
    "\n",
    "            if split:\n",
    "                self.data = self.data[self.data['split'] == split]\n",
    "\n",
    "            self.label_map = labels_json if isinstance(labels_json, dict) else None\n",
    "\n",
    "            for _, row in self.data.iterrows():\n",
    "                relative_path = row['image_path'].replace(\"\\\\\", \"/\")\n",
    "                image_path = os.path.join(images_dir, relative_path)\n",
    "                image_path = os.path.normpath(image_path)\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(row['label'])\n",
    "\n",
    "        else:\n",
    "            self.image_paths = [\n",
    "                os.path.join(images_dir, fname)\n",
    "                for fname in os.listdir(images_dir)\n",
    "                if os.path.isfile(os.path.join(images_dir, fname))\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_train:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            return image, image_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20233196159122085\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"/home/an/spbu_deep_learning/classification/new_annotations.csv\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomRotation(15),      \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "train_dataset = OnePieceDataset(\n",
    "    images_dir=TRAIN_DATA_PATH,\n",
    "    csv_path=CSV_PATH,\n",
    "    labels_json=LABELS_MAPPING,\n",
    "    transform=transform,\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "val_dataset = OnePieceDataset(\n",
    "    images_dir=TRAIN_DATA_PATH,\n",
    "    csv_path=CSV_PATH,\n",
    "    labels_json=LABELS_MAPPING,\n",
    "    transform=transform,\n",
    "    split=\"val\"\n",
    ")\n",
    "\n",
    "print(len(val_dataset) / (len(train_dataset) + len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/an/ml_hw/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/an/ml_hw/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/an/ml_hw/lib/python3.10/site-packages/PIL/Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 1.2942, Train Accuracy: 67.39%\n",
      "Epoch Time: 22.25 seconds\n",
      "Epoch 2/10\n",
      "Train Loss: 0.3426, Train Accuracy: 92.49%\n",
      "Epoch Time: 22.04 seconds\n",
      "Epoch 3/10\n",
      "Train Loss: 0.1728, Train Accuracy: 96.12%\n",
      "Epoch Time: 21.56 seconds\n",
      "Epoch 4/10\n",
      "Train Loss: 0.1140, Train Accuracy: 97.87%\n",
      "Epoch Time: 21.45 seconds\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0663, Train Accuracy: 99.11%\n",
      "Epoch Time: 21.40 seconds\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0456, Train Accuracy: 99.52%\n",
      "Epoch Time: 20.91 seconds\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0327, Train Accuracy: 99.66%\n",
      "Epoch Time: 21.03 seconds\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0259, Train Accuracy: 99.83%\n",
      "Epoch Time: 20.87 seconds\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0182, Train Accuracy: 99.90%\n",
      "Epoch Time: 20.89 seconds\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0217, Train Accuracy: 99.90%\n",
      "Epoch Time: 20.98 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "import time\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 1e-5  \n",
    "\n",
    "CSV_PATH = \"/home/an/spbu_deep_learning/classification/train_annotations.csv\"\n",
    "\n",
    "train_dataset = OnePieceDataset(images_dir=TRAIN_DATA_PATH, csv_path=CSV_PATH, labels_json=LABELS_MAPPING, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(LABELS_MAPPING)) \n",
    "# model.classifier[1] = nn.Linear(model.last_channel, len(LABELS_MAPPING))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=12, eta_min=1e-6)\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(dataloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  \n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "        \n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "torch.save(model.state_dict(), \"one_piece_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = OnePieceDataset(images_dir=TEST_DATA_PATH, transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "image_names = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, filenames in test_loader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, preds = outputs.max(1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        image_names.extend(filenames)\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': image_names,\n",
    "    'label': predictions\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
